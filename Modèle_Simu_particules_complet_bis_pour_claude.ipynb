{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon May 22 14:13:15 2023\n",
    "\n",
    "@author: souchaud\n",
    "\"\"\"\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import trackpy as tp\n",
    "import functions_analyze as lib\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device for torch operations:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_field_inbox(coordinates_diff, distances, Req, R0, Frep, Fadh,\n",
    "                      coeff_a = None, coeff_rep = None):\n",
    "    \"\"\"\n",
    "    Calculate the force field within the focal box.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - coordinates_diff: Tensor representing the positions of particles in the focal box.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - force_field: Tensor representing the force field within the focal box.\n",
    "\n",
    "    \"\"\"  \n",
    "    Rlim = 0.000001\n",
    "    R = torch.norm(coordinates_diff, dim=2)\n",
    "    # prevents the repulsion force from exploding when approaching its maximum value\n",
    "    R = torch.where(R > Rlim*torch.ones(1, device=device),\n",
    "                  R, Rlim*torch.ones(1, device=device)).to(device)\n",
    "    \n",
    "    ###########  R**2 adhesion force ###########\n",
    "    # a = coeff_a\n",
    "    # b = (Fadh-a*(R0**2-Req**2))/(R0-Req)\n",
    "    # c = -Req*(a*Req+ (Fadh-a*(R0**2-Req**2))/(R0-Req))\n",
    "    # force = torch.where(torch.logical_and(R < R0, R > Req),\n",
    "    #                     -(a*R**2+b*R+c), torch.zeros_like(R)).to(device)\n",
    "    \n",
    "    ########### a*R**alpha + b ############\n",
    "    alpha = coeff_a\n",
    "    # force = torch.where(torch.logical_and(R < R0, R > Req),\n",
    "    #                     -(Fadh/((R0**alpha)-(Req**alpha)))*((R**alpha)-(Req**alpha)), torch.zeros_like(R)).to(device)\n",
    "    force = torch.where(torch.logical_and(R < R0, R > Req),\n",
    "                        function_adh(R, Req, R0, Fadh, alpha, coeff_a=coeff_a), torch.zeros_like(R)).to(device)\n",
    "\n",
    "    # The repulsion force is calculated wherever R<Req\n",
    "    ########### Linear adhesion force ########### \n",
    "    # force = torch.where(torch.logical_and(R < R0, R > Req),\n",
    "    #                     -((Fadh/(R0-Req))*R-Fadh*Req/(R0-Req)), torch.zeros_like(R)).to(device)\n",
    "\n",
    "    ###########  Repulsion force linear ########## \n",
    "    # force = torch.where(R < Req,\n",
    "    #                     - Frep*R*(1/Req-1/R), force).to(device)\n",
    "    ########### Repulsion forces in 1/R ########### \n",
    "    force = torch.where(R <= Req,\n",
    "                        - Frep*coeff_rep*(1/Req-1/R), force).to(device)\n",
    "\n",
    "    force_field = torch.sum(force[:, :, None] *\n",
    "                            torch.nn.functional.normalize(coordinates_diff, dim = 2), axis=1)\n",
    "\n",
    "    return force_field\n",
    "\n",
    "\n",
    "def function_adh(R, Req, R0, Fadh, alpha, coeff_a):\n",
    "    # a = coeff_a\n",
    "    # b = (Fadh-a*(R0**2-Req**2))/(R0-Req)\n",
    "    # c = -Req*(a*Req+ (Fadh-a*(R0**2-Req**2))/(R0-Req))\n",
    "    # return -(a*R**2+b*R+c)\n",
    "    return -((Fadh/(R0-Req))*R-Fadh*Req/(R0-Req))\n",
    "\n",
    "\n",
    "def plot_environment(cells, space_size,req, path_saving=None, iteration=None):\n",
    "    fig, axis = plt.subplots(figsize=(6, 6))\n",
    "    plt.xlim(0, space_size)\n",
    "    plt.ylim(0, space_size)\n",
    "\n",
    "    # Combine cells from both populations\n",
    "    all_cells = population1.cells + population2.cells\n",
    "\n",
    "    # Extract x and y coordinates\n",
    "    x = [cell.position[0].item() for cell in all_cells]\n",
    "    y = [cell.position[1].item() for cell in all_cells]\n",
    "\n",
    "    # Create a list of colors corresponding to each cell\n",
    "    colors = ['blue'] * len(population1.cells) + \\\n",
    "        ['red'] * len(population2.cells)\n",
    "\n",
    "    # Plot all cells at once with the specified colors\n",
    "    axis.scatter(x, y, s=3, color=colors,alpha=0.5, rasterized=True)\n",
    "\n",
    "    # plt.title('Cell Movement')\n",
    "    plt.xlabel('X position (micrometers)')\n",
    "    plt.ylabel('Y position (micrometers)')\n",
    "    # plt.axis('off')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'{path_saving}image_{iteration}.png',\n",
    "                bbox_inches='tight', dpi=400, pad_inches = 0)\n",
    "\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "    # print(iteration)\n",
    "\n",
    "\n",
    "def plot_function(pas, Req, R0, Frep, Fadh, a, coeff_rep):\n",
    "\n",
    "    b = (Fadh-a*(R0**2-Req**2))/(R0-Req)\n",
    "    c = -Req*(a*Req + (Fadh-a*(R0**2-Req**2))/(R0-Req))\n",
    "\n",
    "    fig, axis = plt.subplots(figsize=(6, 6))\n",
    "    plt.xlim(0, R0)\n",
    "    plt.ylim(-Frep, Fadh)\n",
    "\n",
    "    print(\"Req = \", Req)\n",
    "    print(\"R0 = \", R0)\n",
    "    print(\"Fadh = \", Fadh)\n",
    "    print(\"Frep = \", Frep)\n",
    "\n",
    "    axis.plot(np.arange(pas, Req, pas), [\n",
    "              R*Frep*(1/Req-1/R) for R in np.arange(pas, Req, pas)], label='rep Mathieu')\n",
    "    axis.plot(np.arange(pas, Req, pas), [\n",
    "              Frep*coeff_rep*(1/Req-1/R) for R in np.arange(pas, Req, pas)], label='rep Alex')\n",
    "\n",
    "    axis.plot(np.arange(Req, R0, pas), [\n",
    "              (Fadh/(R0-Req))*(R-Req) for R in np.arange(Req, R0, pas)], label='adhline')\n",
    "    axis.plot(np.arange(Req, R0, pas), [-function_adh(R, Req, R0, Fadh, alpha=0.5, coeff_a=30)\n",
    "                                        for R in np.arange(Req, R0, pas)], alpha=0.5, label='adh_Alex')\n",
    "    axis.plot(np.arange(Req, R0, pas), [(a*R**2+b*R+c)\n",
    "              for R in np.arange(Req, R0, pas)], label=\"square\")\n",
    "\n",
    "    # (Fadh/(R0-Req))*R+Fadh*Req/(R0-Req)\n",
    "\n",
    "    plt.xlabel('Distance')\n",
    "    plt.ylabel('Force')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellAgent:\n",
    "    def __init__(self, id, pop, position, velocity,\n",
    "                 velocity_magnitude, persistence, space_size,\n",
    "                 tau, noise):\n",
    "        self.id = id  # ID unique de la cellule\n",
    "        self.pop = pop\n",
    "        self.position_init = position.clone().to(device)\n",
    "        self.position = position.clone().to(device)\n",
    "        self.velocity = velocity.clone().to(device)\n",
    "        self.velocity_magnitude = velocity_magnitude\n",
    "        self.persistence = persistence\n",
    "        self.space_size = space_size\n",
    "        self.tau = tau\n",
    "        self.noise = noise\n",
    "        self.direction = torch.nn.functional.normalize(velocity, p=2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Population:\n",
    "    def __init__(self, num_cells, space_size, velocity_magnitude,\n",
    "                 persistence, min_distance, pop_tag, ecart_type,\n",
    "                 tau, noise):\n",
    "        self.num_cells = num_cells\n",
    "        self.space_size = space_size\n",
    "        self.velocity_magnitude = velocity_magnitude\n",
    "        self.persistence = persistence\n",
    "        self.min_distance = min_distance\n",
    "        self.pop_tag = pop_tag  # Identifiant de la population\n",
    "        self.ecart_type = ecart_type  # Initialisation de l'Ã©cart type\n",
    "        self.tau = tau\n",
    "        self.noise = noise\n",
    "        self.cells = []\n",
    "        self.initialize_cells()\n",
    "\n",
    "    def initialize_cells(self):\n",
    "        global cell_id_counter  # Utilisez cell_id_counter comme un compteur global\n",
    "        positions = torch.rand((self.num_cells, 2), device=device) * self.space_size\n",
    "        directions = torch.nn.functional.normalize(torch.empty_like(positions).uniform_(-1, 1), dim=1)\n",
    "        vitesses_gaussiennes = torch.normal(mean=self.velocity_magnitude, std=self.ecart_type, size=(self.num_cells,))\n",
    "\n",
    "        # Logique pour placer les cellules en respectant la distance minimale\n",
    "        if self.min_distance != 0:\n",
    "            grid_size = int(np.ceil(self.space_size / self.min_distance))\n",
    "            grid = [[[] for _ in range(grid_size)] for _ in range(grid_size)]\n",
    "            \n",
    "            for i, position in enumerate(positions):\n",
    "                # Logique de placement en respectant la distance minimale\n",
    "                placed = False\n",
    "                while not placed:\n",
    "                    grid_x = int(position[0] / self.min_distance)\n",
    "                    grid_y = int(position[1] / self.min_distance)\n",
    "                    conflicts = any(torch.norm(position - other_position) < self.min_distance for other_position in grid[grid_x][grid_y])\n",
    "                    if not conflicts:\n",
    "                        for dx in [-1, 0, 1]:\n",
    "                            for dy in [-1, 0, 1]:\n",
    "                                if dx == 0 and dy == 0:\n",
    "                                    continue\n",
    "                                nx, ny = grid_x + dx, grid_y + dy\n",
    "                                if 0 <= nx < grid_size and 0 <= ny < grid_size:\n",
    "                                    conflicts = any(torch.norm(position - other_position) < self.min_distance for other_position in grid[nx][ny])\n",
    "                                    if conflicts:\n",
    "                                        break\n",
    "                            if conflicts:\n",
    "                                break\n",
    "                    if not conflicts:\n",
    "                        placed = True\n",
    "                        grid[grid_x][grid_y].append(position)\n",
    "                        # velocity = directions[i] * vitesses_gaussiennes[i]\n",
    "                        # self.cells.append(CellAgent(cell_id_counter, position, velocity, vitesses_gaussiennes[i], self.persistence, self.space_size))\n",
    "                        # cell_id_counter += 1\n",
    "                        velocity = directions[i] * vitesses_gaussiennes[i]\n",
    "                        self.cells.append(CellAgent(cell_id_counter, self.pop_tag, position, velocity,\n",
    "                                                    vitesses_gaussiennes[i], self.persistence, self.space_size,\n",
    "                                                    self.tau, self.noise,\n",
    "                                                    ))\n",
    "                        cell_id_counter += 1\n",
    "                        placed = True  # Assurez-vous que cela est correctement gÃ©rÃ© dans votre logique\n",
    "                    else:\n",
    "                        position = torch.rand(2, device=device) * self.space_size\n",
    "        else:\n",
    "            # for i, position in enumerate(positions):\n",
    "            #     velocity = directions[i] * vitesses_gaussiennes[i]\n",
    "            #     self.cells.append(CellAgent(cell_id_counter, position, velocity, vitesses_gaussiennes[i], self.persistence, self.space_size))\n",
    "            #     cell_id_counter += 1\n",
    "            for i, position in enumerate(positions):\n",
    "                velocity = directions[i] * vitesses_gaussiennes[i]\n",
    "                self.cells.append(CellAgent(cell_id_counter, self.pop_tag, position, velocity,\n",
    "                                                    vitesses_gaussiennes[i], self.persistence, self.space_size,\n",
    "                                                    self.tau, self.noise,\n",
    "                                                    ))\n",
    "                cell_id_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Surface:\n",
    "    def get_friction(self, position):\n",
    "        friction = torch.empty(1).uniform_(0, 0.2).to(device)\n",
    "        return friction.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DÃ©finitions des diffÃ©rents paramÃ¨tres de la simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = True\n",
    "# In[Simulation parameters]\n",
    "# Space parameters\n",
    "SPACE_SIZE = 2048 # 2048 #1308 # Micrometers\n",
    "\n",
    "# time settings\n",
    "TIME_SIMU = 90 # time simulation in minutes\n",
    "DELTA_T = 0.01 # 0.01 # 15/60 # 0.01 # simulation interval in minutes\n",
    "PLOT_INTERVAL = 100 # 25\n",
    "\n",
    "# simulation parameters\n",
    "MU = 1 #1  # mobility in min.kg-1\n",
    "F_REP = 40  # repulsive strength\n",
    "F_ADH = 7 # 3 #4 #attractive strength force kg.um.min-2\n",
    "R_EQ = 1.1 # 11  # equilibrium radius in um\n",
    "R_0 = 1.6 # 16  # interaction radius in um\n",
    "MIN_DISTANCE_INIT = R_EQ\n",
    "COEFF_CARRE = 50\n",
    "COEFF_REP = 0.5\n",
    "plot_function(pas=0.01, Req=R_EQ, R0=R_0, Frep=F_REP,\n",
    "              Fadh=F_ADH, a=COEFF_CARRE, coeff_rep=COEFF_REP)\n",
    "\n",
    "# factor simulation\n",
    "FLUCTUATION_FACTOR = 3 #4\n",
    "\n",
    "# Cells definition\n",
    "PACKING_FRACTION = 0.00005\n",
    "N_CELLS = int((PACKING_FRACTION*SPACE_SIZE**2)/\n",
    "              (math.pi*((R_EQ/2)**2)))  # number of particles\n",
    "print(N_CELLS, \"cells\")\n",
    "# Population 1 parameters\n",
    "velocity_magnitude_pop1 = 3 #um/min\n",
    "ECART_TYPE_POP1 = 0.3\n",
    "NOISE_POP_1 = 8 # noise intensity on the angle at each step\n",
    "TAU_POP_1 = 5 # characteristic time for the polarization to align in the scattering direction defined by v=dr/dt = time\n",
    "PERSISTENCE_POP1 = 0 #0.1\n",
    "# Population 2 parameters\n",
    "velocity_magnitude_pop2 = 8 # um/min\n",
    "ECART_TYPE_POP2 = 0.5\n",
    "NOISE_POP_2 = 5\n",
    "TAU_POP_2 = 5\n",
    "PERSISTENCE_POP2 = 0 #0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_id_counter = 0  # Commencez le comptage des ID Ã  partir de 0\n",
    "# In[Definition of the populations]\n",
    "population1 = Population(num_cells=int(N_CELLS/2), space_size=SPACE_SIZE,\n",
    "                         velocity_magnitude=velocity_magnitude_pop1,\n",
    "                         persistence=PERSISTENCE_POP1, ecart_type=ECART_TYPE_POP1,\n",
    "                         min_distance=MIN_DISTANCE_INIT, pop_tag=\"Population 1\",\n",
    "                         tau = TAU_POP_1, noise=NOISE_POP_1)\n",
    "\n",
    "population2 = Population(num_cells=int(N_CELLS/2), space_size=SPACE_SIZE,\n",
    "                         velocity_magnitude=velocity_magnitude_pop2,\n",
    "                         persistence=PERSISTENCE_POP2, ecart_type=ECART_TYPE_POP2,\n",
    "                         min_distance=MIN_DISTANCE_INIT, pop_tag=\"Population 2\",\n",
    "                         tau = TAU_POP_2, noise=NOISE_POP_2)\n",
    "\n",
    "cells = population1.cells + population2.cells\n",
    "\n",
    "surface = Surface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[initialisation]\n",
    "positions = torch.stack([cell.position_init for cell in cells])\n",
    "V0 = torch.tensor([cell.velocity_magnitude for cell in cells], device = device).unsqueeze(1)\n",
    "direction = torch.stack([cell.direction for cell in cells])\n",
    "positions = torch.stack([cell.position for cell in cells])\n",
    "\n",
    "if PLOT : \n",
    "    PATH = f'/Users/souchaud/Desktop/simu/v1{velocity_magnitude_pop1}v2{velocity_magnitude_pop2}a{COEFF_CARRE}coefrep{COEFF_REP}fadh{F_ADH}frep{F_REP}/'\n",
    "    if not os.path.exists(PATH):\n",
    "        os.mkdir(PATH)\n",
    "    else :\n",
    "        print(\"WARNING : FOLDER DOES ALREADY EXIST!\")\n",
    "        sys.exit(0)\n",
    "    plot_environment(cells, space_size= SPACE_SIZE, req=R_EQ,\n",
    "                    path_saving=PATH, iteration = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autovel(dX, n, tau, noise, dt, persistence):\n",
    "    \"\"\"\n",
    "    Calcule la nouvelle direction des cellules basÃ©e sur leur dÃ©placement,\n",
    "    leur direction prÃ©cÃ©dente, le bruit, le temps caractÃ©ristique tau, et la persistance.\n",
    "    \n",
    "    ParamÃ¨tres\n",
    "    ----------\n",
    "    dX : Tensor\n",
    "        Le dÃ©placement des cellules durant le dernier intervalle de temps.\n",
    "    n : Tensor\n",
    "        La direction actuelle des cellules.\n",
    "    tau : float\n",
    "        Le temps caractÃ©ristique pour l'alignement de la polarisation dans\n",
    "        la direction dÃ©finie par la vitesse = dX/dt.\n",
    "    noise : float\n",
    "        L'intensitÃ© du bruit ajoutÃ© pour simuler des perturbations alÃ©atoires\n",
    "        dans la direction des cellules.\n",
    "    dt : float\n",
    "        L'intervalle de temps entre les mises Ã  jour des positions.\n",
    "    persistence : float\n",
    "        Le facteur de persistance qui influence Ã  quel point la direction actuelle\n",
    "        est conservÃ©e. Valeur entre 0 (pas de persistance, direction entiÃ¨rement alÃ©atoire)\n",
    "        et 1 (persistance complÃ¨te, pas de changement de direction).\n",
    "\n",
    "    Retour\n",
    "    -------\n",
    "    new_direction : Tensor\n",
    "        La nouvelle direction des cellules aprÃ¨s mise Ã  jour.\n",
    "    \"\"\"    \n",
    "     # Normalize the input vector\n",
    "    dX_norm = torch.nn.functional.normalize(dX, dim=1) * 0.9999999\n",
    "    if persistence == 1:\n",
    "        persistence = 0.9999999\n",
    "    # Compute the angle between the input vector and the x-axis\n",
    "    theta = torch.atan2(dX_norm[:, 1], dX_norm[:, 0]).to(device)\n",
    "    \n",
    "    # Compute the change in angle based on the orientation vector (n)\n",
    "    dtheta = torch.arcsin((n[:, 0] * dX_norm[:, 1] - n[:, 1] * dX_norm[:, 0])) * dt / tau # * (1 - persistence))\n",
    "\n",
    "    # Generate random noise for angle perturbation\n",
    "    rnd = (2 * math.pi * (torch.rand(len(dX), 1, device=device) - 0.5)) * noise * np.sqrt(dt) #* (1 - persistence)\n",
    "    \n",
    "    # Capture de theta avant sa mise Ã  jour\n",
    "    initial_theta = theta.clone()  # Utilisez clone() pour Ã©viter les modifications inattendues\n",
    "    # Update the angle by adding the change in angle, random noise, and the previous angle\n",
    "    theta_update = initial_theta + dtheta + rnd.squeeze(1)\n",
    "\n",
    "    # Calculate the weighted average of the new direction and the old direction\n",
    "    new_dir_x = torch.cos(theta_update) #* (1 - persistence) + n[:, 0] * persistence\n",
    "    new_dir_y = torch.sin(theta_update) #* (1 - persistence) + n[:, 1] * persistence\n",
    "    \n",
    "    # CrÃ©er un nouveau tenseur pour la direction mise Ã  jour au lieu de modifier n\n",
    "    new_direction = torch.stack((new_dir_x, new_dir_y), dim=1)\n",
    "    \n",
    "    # Retourne la nouvelle direction, rnd, dtheta, et initial_theta\n",
    "    return new_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the circle to compare angles \n",
    "        # if abs(angle) > 1.5:\n",
    "        #     print(\"Pop1\", i, \"direct\", cell.direction, \"newdire\", new_direction,\n",
    "        #           \"angle\", angle, \"disp\", cell_displacement, \"init theta\", initial_theta,\n",
    "        #           \"random\", rnd)\n",
    "        #     fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        #     # Cercle unitaire\n",
    "        #     circle = plt.Circle((0, 0), 1, color='blue', fill=False)\n",
    "        #     ax.add_artist(circle)\n",
    "        #     # Ajouter les vecteurs\n",
    "        #     for direction, color, label in zip([cell.direction.unsqueeze(0), new_direction], ['red', 'green'], ['n', 'new_direction']):\n",
    "        #         ax.quiver(0, 0, direction[0, 0], direction[0, 1], angles='xy', scale_units='xy', scale=1, color=color, label=label)\n",
    "        #     # Configuration du graphique\n",
    "        #     ax.set_xlim(-1.5, 1.5)\n",
    "        #     ax.set_ylim(-1.5, 1.5)\n",
    "        #     ax.set_aspect('equal')\n",
    "        #     plt.xlabel('X')\n",
    "        #     plt.ylabel('Y')\n",
    "        #     plt.title('Vecteurs sur un cercle trigonomÃ©trique')\n",
    "        #     plt.legend()\n",
    "        #     plt.grid(True)\n",
    "        #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[Simulation]\n",
    "time = 0\n",
    "iteration = 1\n",
    "MAX_DISTANCE = np.sqrt(2*(SPACE_SIZE/2)**2)\n",
    "# CrÃ©ation du data_list vide pour crÃ©er la liste qui deviendra le dataFrame\n",
    "data_list = []\n",
    "while time < TIME_SIMU :\n",
    "    #Paiwise distance.\n",
    "    coordinates_diff = ((positions[:, None, :] - positions[None, :, :]))\n",
    "    coordinates_diff = torch.remainder(coordinates_diff-(SPACE_SIZE/2),SPACE_SIZE)-(SPACE_SIZE/2)\n",
    "    distances = torch.stack([torch.norm(coordinates_diff[i], dim=1)\n",
    "                             for i in range(0, len(coordinates_diff))])\n",
    "    is_greater_than_max = torch.any(distances > MAX_DISTANCE)\n",
    "\n",
    "    if is_greater_than_max:\n",
    "      print(\"At least one distance is greater than the max distance.\")\n",
    "\n",
    "    # force_field calculation\n",
    "    force_field = force_field_inbox(coordinates_diff, distances, Req=R_EQ,\n",
    "                                    R0=R_0, Frep=F_REP, Fadh=F_ADH,\n",
    "                                    coeff_a = COEFF_CARRE, coeff_rep = 0.5)\n",
    "    \n",
    "    # displacement computing\n",
    "    fluctuations = (torch.rand(V0.shape, device=V0.device) - 0.5) * FLUCTUATION_FACTOR\n",
    "    displacement = MU * force_field * DELTA_T + (V0 + fluctuations) * direction * DELTA_T\n",
    "    positions += displacement\n",
    "\n",
    "    # border conditions\n",
    "    positions = torch.remainder(positions, SPACE_SIZE)\n",
    "\n",
    "    # Mise Ã  jour de la position et de la direction pour chaque cellule\n",
    "    for cell, disp in zip(cells, displacement):\n",
    "        # Mise Ã  jour de la position de la cellule\n",
    "        cell.position += disp\n",
    "        cell.position = torch.remainder(cell.position, SPACE_SIZE)\n",
    "        \n",
    "        # Mise Ã  jour de la direction de la cellule\n",
    "        new_direction = autovel(disp.unsqueeze(0), cell.direction.unsqueeze(0), cell.tau, cell.noise, DELTA_T, persistence=cell.persistence)\n",
    "        cell.direction = new_direction.squeeze(0)\n",
    "        # Ajouter les informations de la cellule Ã  la liste temporaire\n",
    "        data_list.append({\n",
    "            'frame': time,\n",
    "            'particle': cell.id,\n",
    "            'pop_tag': cell.pop,  # Inclure le tag de la population ici\n",
    "            'x': cell.position[0].item(),\n",
    "            'y': cell.position[1].item(),\n",
    "            'dir_x': cell.direction[0].item(),\n",
    "            'dir_y': cell.direction[1].item()\n",
    "             })\n",
    "\n",
    "    # plot the result\n",
    "    if PLOT:\n",
    "        marker_radius = 1.1\n",
    "        marker_size = (np.pi) * marker_radius ** 2\n",
    "        if iteration % PLOT_INTERVAL == 0:\n",
    "            plot_environment(cells, path_saving = PATH, space_size = SPACE_SIZE, req=R_EQ, iteration = iteration)\n",
    "\n",
    "    # AprÃ¨s avoir mis Ã  jour toutes les cellules\n",
    "    direction = torch.stack([cell.direction for cell in cells])\n",
    "    # Mise Ã  jour du temps\n",
    "    time += DELTA_T\n",
    "    # print(time)\n",
    "    iteration += 1\n",
    "\n",
    "    # CrÃ©ation du DataFrame Ã  partir de la liste temporaire aprÃ¨s la boucle\n",
    "data_frame = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_positions_xy(group, dt, space_size):\n",
    "    # Calculer les diffÃ©rences pour obtenir 'dx' et 'dy', en prenant en compte la nature toroÃ¯dale\n",
    "    group['dx'] = group['x'].diff().fillna(0)\n",
    "    group['dy'] = group['y'].diff().fillna(0)\n",
    "\n",
    "    # Correction pour la nature toroÃ¯dale de l'espace\n",
    "    group['dx'] = np.where(group['dx'] > space_size / 2, group['dx'] - space_size,\n",
    "                           np.where(group['dx'] < -space_size / 2, group['dx'] + space_size, group['dx']))\n",
    "    group['dy'] = np.where(group['dy'] > space_size / 2, group['dy'] - space_size,\n",
    "                           np.where(group['dy'] < -space_size / 2, group['dy'] + space_size, group['dy']))\n",
    "    \n",
    "    # Calculer les nouvelles positions ajustÃ©es\n",
    "    group['adjusted_x'] = group['x'].iloc[0] + group['dx'].cumsum()\n",
    "    group['adjusted_y'] = group['y'].iloc[0] + group['dy'].cumsum()\n",
    "\n",
    "    # # Assurer que les valeurs restent dans l'espace toroÃ¯dal\n",
    "    # group['adjusted_x'] %= space_size\n",
    "    # group['adjusted_y'] %= space_size\n",
    "\n",
    "    # Calculer la distance parcourue Ã  chaque pas de temps\n",
    "    group['distance'] = np.sqrt(group['dx']**2 + group['dy']**2)\n",
    "\n",
    "    # Calculer la vitesse pour chaque pas de temps\n",
    "    group['vitesse'] = group['distance'] / dt\n",
    "\n",
    "    # Remplacer les colonnes 'x' et 'y' par les valeurs ajustÃ©es\n",
    "    group['x'], group['y'] = group['adjusted_x'], group['adjusted_y']\n",
    "\n",
    "    # Supprimer les colonnes temporaires inutiles\n",
    "    group.drop(['adjusted_x', 'adjusted_y', 'dx', 'dy'], axis=1, inplace=True)\n",
    "\n",
    "    return group\n",
    "\n",
    "# Fonction pour calculer l'angle en degrÃ©s entre deux vecteurs de direction successifs\n",
    "def angle_between_directions(row):\n",
    "    # Extract direction components\n",
    "    dx1, dy1 = row['dir_x'], row['dir_y']\n",
    "    dx2, dy2 = row['dir_x_next'], row['dir_y_next']\n",
    "    \n",
    "    # Calculate initial and final angles using arctan2 for each direction vector\n",
    "    angle_initial = np.arctan2(dy1, dx1)\n",
    "    angle_final = np.arctan2(dy2, dx2)\n",
    "    \n",
    "    # Calculate the angle difference\n",
    "    angle_change = angle_final - angle_initial\n",
    "    \n",
    "    if angle_change > np.pi : \n",
    "        angle_change = angle_change - 2 * np.pi\n",
    "    if angle_change < -np.pi:\n",
    "        angle_change = angle_change + 2 * np.pi\n",
    "\n",
    "    return angle_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer la fonction Ã  chaque groupe de particules en utilisant lambda pour inclure DELTA_T comme argument dt\n",
    "df = data_frame.groupby('particle').apply(lambda group: adjust_positions_xy(group, dt=DELTA_T, space_size=SPACE_SIZE)).reset_index(drop=True)\n",
    "\n",
    "# Assurez-vous que votre DataFrame est triÃ© par particule et par frame\n",
    "df.sort_values(by=['particle', 'frame'], inplace=True)\n",
    "\n",
    "# DÃ©caler les directions pour obtenir le vecteur direction au temps t+1 pour chaque particule\n",
    "df['dir_x_next'] = df.groupby('particle')['dir_x'].shift(-1)\n",
    "df['dir_y_next'] = df.groupby('particle')['dir_y'].shift(-1)\n",
    "\n",
    "# Appliquer la fonction pour calculer l'angle entre les directions successives\n",
    "df['angle_change'] = df.apply(angle_between_directions, axis=1)\n",
    "\n",
    "# Optionnel : Supprimer les lignes oÃ¹ la direction suivante est NaN, ce qui se produit pour la derniÃ¨re observation de chaque particule\n",
    "df.dropna(subset=['dir_x_next', 'dir_y_next'], inplace=True)\n",
    "\n",
    "# Calculer la vitesse moyenne pour chaque particule\n",
    "vitesse_moyenne = df.groupby('particle')['vitesse'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrÃ©er une nouvelle figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Tracer l'histogramme pour 'angle_change' (normalisÃ©)\n",
    "plt.hist(df[df['pop_tag']=='Population 1']['angle_change'], bins=100, alpha=0.1, color='blue', label='angle_change pop1', density=True)\n",
    "plt.hist(df[df['pop_tag']=='Population 2']['angle_change'], bins=100, alpha=0.1, color='red', label='angle_change pop2', density=True)\n",
    "\n",
    "# Ajouter une lÃ©gende\n",
    "plt.legend()\n",
    "# plt.ylim(0, 0.001)\n",
    "plt.xlim([-np.pi, np.pi])\n",
    "# Ajouter des labels et un titre\n",
    "plt.xlabel('Valeurs')\n",
    "plt.ylabel('DensitÃ©')\n",
    "plt.title('Histogramme normalisÃ© de rnd et angle change')\n",
    "# Afficher la figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrÃ©er une figure et deux subplots (axes) sur une grille de 1x2\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))  # La figure a 1 ligne et 2 colonnes de graphiques\n",
    "\n",
    "# Tracer le premier histogramme sur le premier axe (panneau)\n",
    "axs[0].hist(df['vitesse'], bins = 100)\n",
    "axs[0].set_title('Histogramme des vitesses instantanÃ©es')\n",
    "axs[0].set_xlabel('Vitesse [um/min]')\n",
    "axs[0].set_ylabel('Nombre de particules')\n",
    "\n",
    "# Tracer le second histogramme sur le second axe (panneau)\n",
    "axs[1].hist(vitesse_moyenne, bins=50)\n",
    "# axs[1].set_xlim(4, 6)  # DÃ©commentez et ajustez si nÃ©cessaire\n",
    "axs[1].set_title('Histogramme des vitesses moyennes')\n",
    "axs[1].set_xlabel('Vitesse moyenne [um/min]')\n",
    "axs[1].set_ylabel('Nombre de particules')\n",
    "\n",
    "# Ajuster l'espacement entre les subplots pour Ã©viter le chevauchement des titres et des Ã©tiquettes\n",
    "plt.tight_layout()\n",
    "\n",
    "# Afficher la figure contenant les deux subplots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "tp.plot_traj(traj=df)\n",
    "# Rendre les Ã©chelles des axes x et y Ã©gales\n",
    "ax.set_aspect('equal', 'box')\n",
    "# Ajouter un titre\n",
    "ax.set_title('Trajectory of Particle 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supposons que df_adjusted est votre DataFrame aprÃ¨s ajustements avec 'particle', 'x', et 'y'\n",
    "particle_df = df[df['particle'] == 219]\n",
    "fig, ax = plt.subplots()\n",
    "tp.plot_traj(particle_df, mpp=0.637, fps=1, ax=ax)\n",
    "# Rendre les Ã©chelles des axes x et y Ã©gales\n",
    "ax.set_aspect('equal', 'box')\n",
    "# Ajouter un titre\n",
    "ax.set_title('Trajectory of Particle 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msd = df.copy()\n",
    "df_msd['frame'] = df_msd.groupby('particle').cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_msd(msd, fps, name=\"MSD of all frames in function of lag time (s)\",\n",
    "             color_plot: str = 'red', save=False, pathway_saving=None,\n",
    "             alpha=0.05, linewidth=0.01, img_type='jpg'):\n",
    "    \"\"\"\n",
    "    Plot the mean square displacement (MSD) for a specific need.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    msd : DataFrame\n",
    "        DataFrame containing the MSD values.\n",
    "    fps : float\n",
    "        Number of frames per second.\n",
    "    name : str, optional\n",
    "        Title of the plot. Default is \"MSD of all frames in function of lag time (s)\".\n",
    "    save : bool, optional\n",
    "        Whether to save the plot or not. Default is False.\n",
    "    pathway_saving : str, optional\n",
    "        Absolute path to save the plot. Default is None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    # Get the number of curves from the number of columns in the MSD DataFrame\n",
    "    nbr_curves = len(msd.columns)\n",
    "\n",
    "    # # Set the index\n",
    "    # msd = msd.set_index(\"lag time [s]\")\n",
    "\n",
    "    # Create a new figure and axis object\n",
    "    fig, axis = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "    # Plot the MSD data on the axis object\n",
    "    axis.plot(msd, alpha=alpha, linewidth=linewidth, color=color_plot)\n",
    "\n",
    "    # Set the limits of the x-axis and y-axis\n",
    "    # axis.set_xlim([1 / fps, 100 / fps])\n",
    "    # axis.set_ylim(0.01, 10000)\n",
    "\n",
    "    # Set the x-axis and y-axis to be on a log scale\n",
    "    axis.set(xscale=\"log\", yscale=\"log\")\n",
    "\n",
    "    # Set the x-axis label\n",
    "    axis.set_xlabel(\"lag time (s)\", fontsize=30)\n",
    "\n",
    "    # Set the x-axis label\n",
    "    axis.set_ylabel(\"MSD\", fontsize=30)\n",
    "\n",
    "    # Add a text box to the plot with the number of curves\n",
    "    textstr = f\"nbre curves: {nbr_curves}\"\n",
    "    props = dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5)\n",
    "    axis.text(0.05, 0.95, textstr, transform=axis.transAxes, fontsize=30,\n",
    "              verticalalignment=\"top\", bbox=props)\n",
    "\n",
    "    axis.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    # Set the title of the plot\n",
    "    fig.suptitle(name, fontsize=40, fontweight=\"bold\", fontstyle='italic', fontname=\"Arial\")\n",
    "\n",
    "    # Adjust the spacing of the plot\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save the plot if the \"save\" parameter is True\n",
    "    if save:\n",
    "        fig.savefig(f\"{pathway_saving}{name}.\" + img_type, format=img_type)\n",
    "\n",
    "\n",
    "IMSD = tp.imsd(df_msd, mpp = 0.637, fps = 0.01)\n",
    "\n",
    "\n",
    "plot_msd(IMSD, fps=0.01, name=\"MSD of all frames in function of lag time (s)\",\n",
    "             color_plot = 'red', save=False, pathway_saving=None,\n",
    "             alpha=1, linewidth=1, img_type='jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [traj clustering with fit and defining a cutoff]\n",
    "LAG_TIME_FIT = 5\n",
    "# plot parameters\n",
    "IMG_TYPE = 'jpg'\n",
    "ALPHA = 0.5\n",
    "LINEWIDTH = 0.1\n",
    "COLOR_SUP = 'blue'\n",
    "COLOR_INF = 'red'\n",
    "color_sup_inf = (COLOR_SUP, COLOR_INF)\n",
    "# Compute et plot the director factor of the imsd\n",
    "\n",
    "COEF_INF, COEF_SUP, PART_COEF_INF, PART_COEF_SUP, CUTOFF =\\\n",
    "   lib.traj_clustering_with_fit_cutoff(df, imsd=IMSD, hist=True,\n",
    "                                        lag_time_fit=LAG_TIME_FIT,\n",
    "                                        micronperpixel=1,\n",
    "                                        fps=0.01, binsize=250,\n",
    "                                        peak_height=50, peak_width=1,\n",
    "                                        save=False, pathway_fig=None,\n",
    "                                        name='all the experiment autocorr', img_type=\"jpg\",\n",
    "                                        plot=True, color_sup_inf=color_sup_inf,\n",
    "                                        cutoff_default=1.4\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer le DataFrame pour une particule spÃ©cifique\n",
    "particle_df = df[df['particle'] == 0].iloc[0:10]\n",
    "particle_df['normdxdy'] = (particle_df['dir_x']**2 + particle_df['dir_y']**2)**0.5\n",
    "fig, ax = plt.subplots()\n",
    "# Tracer la trajectoire de la particule\n",
    "tp.plot_traj(particle_df, mpp=1, fps=15/60, ax = ax)\n",
    "# Obtenir l'axe actuel\n",
    "ax = plt.gca()\n",
    "\n",
    "# Pour chaque point de la trajectoire, ajouter un point reprÃ©sentant la direction\n",
    "for index, row in particle_df.iterrows():\n",
    "    # Le point de dÃ©part du point (position de la particule)\n",
    "    \n",
    "    # Calculer la position du point de direction (en ajoutant un facteur d'Ã©chelle aux composantes de direction si nÃ©cessaire)\n",
    "    dir_x = row['x'] + row['dir_x']*0.01   # Facteur d'Ã©chelle pour dÃ©terminer la position du point de direction\n",
    "    dir_y = row['y'] + row['dir_y']*0.01  # Facteur d'Ã©chelle pour dÃ©terminer la position du point de direction\n",
    "    ax.plot(row['x'], row['y'], 'bo')  # 'ro' crÃ©e un point rond rouge\n",
    "    # Ajouter le point de direction au graphique\n",
    "    ax.plot(dir_x, dir_y, 'ro')  # 'ro' crÃ©e un point rond rouge\n",
    "\n",
    "# Afficher le graphique\n",
    "# Assurer les mÃªmes Ã©chelles en x et y\n",
    "ax.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer le DataFrame pour une particule spÃ©cifique\n",
    "particle_df = df[df['particle'] == 0].iloc[2100:2150]\n",
    "particle_df['normdxdy'] = (particle_df['dir_x']**2 + particle_df['dir_y']**2)**0.5\n",
    "fig, ax = plt.subplots()\n",
    "# Tracer la trajectoire de la particule\n",
    "tp.plot_traj(particle_df, mpp=1, fps=15/60, ax = ax)\n",
    "# Obtenir l'axe actuel\n",
    "ax = plt.gca()\n",
    "\n",
    "# Pour chaque point de la trajectoire, ajouter un point reprÃ©sentant la direction\n",
    "for index, row in particle_df.iterrows():\n",
    "    # Le point de dÃ©part du point (position de la particule)\n",
    "    \n",
    "    # Calculer la position du point de direction (en ajoutant un facteur d'Ã©chelle aux composantes de direction si nÃ©cessaire)\n",
    "    dir_x = row['x'] + row['dir_x']*0.02   # Facteur d'Ã©chelle pour dÃ©terminer la position du point de direction\n",
    "    dir_y = row['y'] + row['dir_y']*0.02  # Facteur d'Ã©chelle pour dÃ©terminer la position du point de direction\n",
    "    ax.plot(row['x'], row['y'], 'bo')  # 'ro' crÃ©e un point rond rouge\n",
    "    # Ajouter le point de direction au graphique\n",
    "    ax.plot(dir_x, dir_y, 'ro')  # 'ro' crÃ©e un point rond rouge\n",
    "\n",
    "# Afficher le graphique\n",
    "# Assurer les mÃªmes Ã©chelles en x et y\n",
    "ax.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer la fonction Ã  chaque groupe de particules en utilisant lambda pour inclure DELTA_T comme argument dt\n",
    "df = data_frame.groupby('particle').apply(lambda group: adjust_positions_xy(group, dt=DELTA_T, space_size=SPACE_SIZE)).reset_index(drop=True)\n",
    "\n",
    "# Assurez-vous que votre DataFrame est triÃ© par particule et par frame\n",
    "df.sort_values(by=['particle', 'frame'], inplace=True)\n",
    "\n",
    "# DÃ©caler les directions pour obtenir le vecteur direction au temps t+1 pour chaque particule\n",
    "df['dir_x_next'] = df.groupby('particle')['dir_x'].shift(-1)\n",
    "df['dir_y_next'] = df.groupby('particle')['dir_y'].shift(-1)\n",
    "\n",
    "# Appliquer la fonction pour calculer l'angle entre les directions successives\n",
    "df['angle_change'] = df.apply(angle_between_directions, axis=1)\n",
    "\n",
    "# Optionnel : Supprimer les lignes oÃ¹ la direction suivante est NaN, ce qui se produit pour la derniÃ¨re observation de chaque particule\n",
    "df.dropna(subset=['dir_x_next', 'dir_y_next'], inplace=True)\n",
    "\n",
    "# Calculer la vitesse moyenne pour chaque particule\n",
    "vitesse_moyenne = df.groupby('particle')['vitesse'].mean()\n",
    "\n",
    "# Tracer l'histogramme des vitesses moyennes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(vitesse_moyenne, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.xlabel('Vitesse moyenne [um/min]')\n",
    "plt.ylabel('Nombre de particules')\n",
    "plt.title('Histogramme des vitesses moyennes des particules')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_step = 10  # Vous pouvez ajuster cette valeur selon vos besoins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from filterpy.kalman import KalmanFilter\n",
    "\n",
    "# Fonction pour appliquer le filtre de Kalman Ã  une sÃ©rie de mesures\n",
    "def apply_kalman_filter(measurements, R, Q):\n",
    "    kf = KalmanFilter(dim_x=1, dim_z=1)\n",
    "    kf.x = np.array([0.])  # initial state\n",
    "    kf.F = np.array([[1.]])  # state transition matrix\n",
    "    kf.H = np.array([[1.]])  # Measurement function\n",
    "    kf.P = np.array([[1.]])  # covariance matrix\n",
    "    kf.R = R  # measurement noise\n",
    "    kf.Q = Q  # process noise\n",
    "    \n",
    "    filtered_measurements = []\n",
    "    for measurement in measurements:\n",
    "        kf.predict()\n",
    "        kf.update(np.array([measurement]))\n",
    "        filtered_measurements.append(kf.x[0])\n",
    "    \n",
    "    return filtered_measurements\n",
    "\n",
    "# Fonction pour sous-Ã©chantillonner et calculer les vitesses moyennes pour chaque cellule avec Kalman\n",
    "def calculate_average_speed_per_cell_with_kalman(df, max_step, delta_t, space_size, R, Q):\n",
    "    particles = df['particle'].unique()\n",
    "    steps = range(1, max_step + 1)\n",
    "    avg_speeds_per_particle = {particle: [] for particle in particles}\n",
    "    filtered_speeds_per_particle = {particle: [] for particle in particles}\n",
    "    \n",
    "    for step in steps:\n",
    "        sub_sampled_df = df.groupby('particle').apply(lambda group: group.iloc[::step]).reset_index(drop=True)\n",
    "        sub_sampled_df = sub_sampled_df.groupby('particle').apply(lambda group: adjust_positions_xy(group, dt=delta_t*step, space_size=space_size)).reset_index(drop=True)\n",
    "        avg_speeds = sub_sampled_df.groupby('particle')['vitesse'].mean()\n",
    "        \n",
    "        for particle in particles:\n",
    "            if particle in avg_speeds:\n",
    "                avg_speeds_per_particle[particle].append(avg_speeds[particle])\n",
    "            else:\n",
    "                avg_speeds_per_particle[particle].append(np.nan)\n",
    "        \n",
    "        # Appliquer le filtre de Kalman pour chaque particule\n",
    "        for particle in particles:\n",
    "            measurements = np.array(avg_speeds_per_particle[particle])\n",
    "            filtered_speeds = apply_kalman_filter(measurements, R, Q)\n",
    "            filtered_speeds_per_particle[particle] = filtered_speeds\n",
    "    \n",
    "    return steps, avg_speeds_per_particle, filtered_speeds_per_particle\n",
    "\n",
    "# Tester diffÃ©rentes valeurs de Q et R\n",
    "R_values = [2e-1, 1e-1, 5e-2]\n",
    "Q_values = [1e-1, 1e-5, 1e-10]\n",
    "\n",
    "# Tracer les rÃ©sultats pour diffÃ©rentes combinaisons de Q et R\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for R in R_values:\n",
    "    for Q in Q_values:\n",
    "        steps, avg_speeds_per_particle, filtered_speeds_per_particle = calculate_average_speed_per_cell_with_kalman(\n",
    "            df, max_step, DELTA_T, SPACE_SIZE, R, Q)\n",
    "        \n",
    "        # Tracer la vitesse moyenne filtrÃ©e pour chaque cellule en fonction de la valeur du pas de temps utilisÃ©\n",
    "        plt.subplot(len(R_values), len(Q_values), R_values.index(R) * len(Q_values) + Q_values.index(Q) + 1)\n",
    "        for particle, avg_speeds in filtered_speeds_per_particle.items():\n",
    "            plt.plot(steps, avg_speeds, marker='o', alpha=0.5, linewidth=0.1, color='blue')\n",
    "        plt.xlabel('Intervalle de temps (pas)')\n",
    "        plt.ylabel('Vitesse moyenne filtrÃ©e [um/min]')\n",
    "        plt.title(f'R={R}, Q={Q}')\n",
    "        plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from filterpy.kalman import KalmanFilter\n",
    "\n",
    "# Fonction pour appliquer le filtre de Kalman Ã  une sÃ©rie de mesures\n",
    "def apply_kalman_filter(measurements, R, Q):\n",
    "    kf = KalmanFilter(dim_x=1, dim_z=1)\n",
    "    kf.x = np.array([0.])  # initial state\n",
    "    kf.F = np.array([[1.]])  # state transition matrix\n",
    "    kf.H = np.array([[1.]])  # Measurement function\n",
    "    kf.P = np.array([[1.]])  # covariance matrix\n",
    "    kf.R = R  # measurement noise\n",
    "    kf.Q = Q  # process noise\n",
    "    \n",
    "    filtered_measurements = []\n",
    "    for measurement in measurements:\n",
    "        kf.predict()\n",
    "        kf.update(np.array([measurement]))\n",
    "        filtered_measurements.append(kf.x[0])\n",
    "    \n",
    "    return filtered_measurements\n",
    "\n",
    "# Fonction pour sous-Ã©chantillonner et calculer les vitesses moyennes pour chaque cellule avec Kalman\n",
    "def calculate_average_speed_per_cell_with_kalman(df, max_step, delta_t, space_size, R, Q):\n",
    "    particles = df['particle'].unique()\n",
    "    steps = range(1, max_step + 1)\n",
    "    avg_speeds_per_particle = {particle: [] for particle in particles}\n",
    "    filtered_speeds_per_particle = {particle: [] for particle in particles}\n",
    "    avg_speeds_pop1 = []\n",
    "    avg_speeds_pop2 = []\n",
    "\n",
    "    for step in steps:\n",
    "        sub_sampled_df = df.groupby('particle').apply(lambda group: group.iloc[::step]).reset_index(drop=True)\n",
    "        sub_sampled_df = sub_sampled_df.groupby('particle').apply(lambda group: adjust_positions_xy(group, dt=delta_t*step, space_size=space_size)).reset_index(drop=True)\n",
    "        avg_speeds = sub_sampled_df.groupby('particle')['vitesse'].mean()\n",
    "        \n",
    "        for particle in particles:\n",
    "            if particle in avg_speeds:\n",
    "                avg_speeds_per_particle[particle].append(avg_speeds[particle])\n",
    "            else:\n",
    "                avg_speeds_per_particle[particle].append(np.nan)\n",
    "        \n",
    "        # Appliquer le filtre de Kalman pour chaque particule\n",
    "        for particle in particles:\n",
    "            measurements = np.array(avg_speeds_per_particle[particle])\n",
    "            filtered_speeds = apply_kalman_filter(measurements, R, Q)\n",
    "            filtered_speeds_per_particle[particle] = filtered_speeds\n",
    "\n",
    "        # Calculer la vitesse moyenne filtrÃ©e pour chaque population\n",
    "        pop1_particles = sub_sampled_df[sub_sampled_df['pop_tag'] == 'Population 1']['particle'].unique()\n",
    "        pop2_particles = sub_sampled_df[sub_sampled_df['pop_tag'] == 'Population 2']['particle'].unique()\n",
    "        \n",
    "        avg_speed_pop1 = np.nanmean([filtered_speeds_per_particle[p] for p in pop1_particles], axis=0)\n",
    "        avg_speed_pop2 = np.nanmean([filtered_speeds_per_particle[p] for p in pop2_particles], axis=0)\n",
    "\n",
    "        avg_speeds_pop1.append(avg_speed_pop1[-1])\n",
    "        avg_speeds_pop2.append(avg_speed_pop2[-1])\n",
    "    \n",
    "    return steps, avg_speeds_per_particle, filtered_speeds_per_particle, avg_speeds_pop1, avg_speeds_pop2\n",
    "\n",
    "# Tester diffÃ©rentes valeurs de Q et R\n",
    "R_values = [2e-1, 1e-1, 5e-2]\n",
    "Q_values = [1e-1, 1e-5, 1e-10]\n",
    "# DÃ©finir les limites des axes\n",
    "x_limits = (1, max_step)\n",
    "y_limits = (0, 10)  # Ajustez ces valeurs selon vos donnÃ©es\n",
    "\n",
    "# Tracer les rÃ©sultats pour diffÃ©rentes combinaisons de Q et R\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for R in R_values:\n",
    "    for Q in Q_values:\n",
    "        steps, avg_speeds_per_particle, filtered_speeds_per_particle, avg_speeds_pop1, avg_speeds_pop2 = calculate_average_speed_per_cell_with_kalman(\n",
    "            df, max_step, DELTA_T, SPACE_SIZE, R, Q)\n",
    "        \n",
    "        # Tracer la vitesse moyenne filtrÃ©e pour chaque cellule en fonction de la valeur du pas de temps utilisÃ©\n",
    "        plt.subplot(len(R_values), len(Q_values), R_values.index(R) * len(Q_values) + Q_values.index(Q) + 1)\n",
    "        for particle, avg_speeds in filtered_speeds_per_particle.items():\n",
    "            plt.plot(steps, avg_speeds, marker='o', alpha=0.5, linewidth=0.1, color='blue')\n",
    "        \n",
    "        # Ajouter les courbes de la vitesse moyenne filtrÃ©e de chaque population\n",
    "        plt.plot(steps, avg_speeds_pop1, marker='o', alpha=0.5, linewidth=2, color='green', label='Population 1')\n",
    "        plt.plot(steps, avg_speeds_pop2, marker='o', alpha=0.5, linewidth=2, color='red', label='Population 2')\n",
    "\n",
    "        plt.xlabel('Intervalle de temps (pas)')\n",
    "        plt.ylabel('Vitesse moyenne filtrÃ©e [um/min]')\n",
    "        plt.title(f'R={R}, Q={Q}')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.xlim(x_limits)\n",
    "        plt.ylim(y_limits)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from filterpy.kalman import KalmanFilter\n",
    "\n",
    "# Fonction pour appliquer le filtre de Kalman Ã  une sÃ©rie de mesures\n",
    "def apply_kalman_filter(measurements, R, Q):\n",
    "    kf = KalmanFilter(dim_x=1, dim_z=1)\n",
    "    kf.x = np.array([0.])  # initial state\n",
    "    kf.F = np.array([[1.]])  # state transition matrix\n",
    "    kf.H = np.array([[1.]])  # Measurement function\n",
    "    kf.P = np.array([[1.]])  # covariance matrix\n",
    "    kf.R = R  # measurement noise\n",
    "    kf.Q = Q  # process noise\n",
    "    \n",
    "    filtered_measurements = []\n",
    "    for measurement in measurements:\n",
    "        kf.predict()\n",
    "        kf.update(np.array([measurement]))\n",
    "        filtered_measurements.append(kf.x[0])\n",
    "    \n",
    "    return filtered_measurements\n",
    "\n",
    "# Fonction pour sous-Ã©chantillonner et calculer les vitesses moyennes pour chaque cellule avec Kalman\n",
    "def calculate_average_speed_per_cell_with_kalman(df, max_step, delta_t, space_size, R, Q):\n",
    "    particles = df['particle'].unique()\n",
    "    steps = range(1, max_step + 1)\n",
    "    avg_speeds_per_particle = {particle: [] for particle in particles}\n",
    "    filtered_speeds_per_particle = {particle: [] for particle in particles}\n",
    "    avg_speeds_pop1 = []\n",
    "    avg_speeds_pop2 = []\n",
    "\n",
    "    for step in steps:\n",
    "        sub_sampled_df = df.groupby('particle').apply(lambda group: group.iloc[::step]).reset_index(drop=True)\n",
    "        sub_sampled_df = sub_sampled_df.groupby('particle').apply(lambda group: adjust_positions_xy(group, dt=delta_t*step, space_size=space_size)).reset_index(drop=True)\n",
    "        avg_speeds = sub_sampled_df.groupby('particle')['vitesse'].mean()\n",
    "        \n",
    "        for particle in particles:\n",
    "            if particle in avg_speeds:\n",
    "                avg_speeds_per_particle[particle].append(avg_speeds[particle])\n",
    "            else:\n",
    "                avg_speeds_per_particle[particle].append(np.nan)\n",
    "        \n",
    "        # Appliquer le filtre de Kalman pour chaque particule\n",
    "        for particle in particles:\n",
    "            measurements = np.array(avg_speeds_per_particle[particle])\n",
    "            filtered_speeds = apply_kalman_filter(measurements, R, Q)\n",
    "            filtered_speeds_per_particle[particle] = filtered_speeds\n",
    "\n",
    "        # Calculer la vitesse moyenne filtrÃ©e pour chaque population\n",
    "        pop1_particles = sub_sampled_df[sub_sampled_df['pop_tag'] == 'Population 1']['particle'].unique()\n",
    "        pop2_particles = sub_sampled_df[sub_sampled_df['pop_tag'] == 'Population 2']['particle'].unique()\n",
    "        \n",
    "        avg_speed_pop1 = np.nanmean([filtered_speeds_per_particle[p] for p in pop1_particles], axis=0)\n",
    "        avg_speed_pop2 = np.nanmean([filtered_speeds_per_particle[p] for p in pop2_particles], axis=0)\n",
    "\n",
    "        avg_speeds_pop1.append(avg_speed_pop1[-1])\n",
    "        avg_speeds_pop2.append(avg_speed_pop2[-1])\n",
    "    \n",
    "    return steps, avg_speeds_per_particle, filtered_speeds_per_particle, avg_speeds_pop1, avg_speeds_pop2\n",
    "\n",
    "# Tester diffÃ©rentes valeurs de Q et R\n",
    "R_values = [3e-1, 1e-1, 1e-1]\n",
    "Q_values = [1e-1, 1e-5, 1e-10]\n",
    "\n",
    "# DÃ©finir les limites des axes\n",
    "x_limits = (1, max_step)\n",
    "y_limits = (0, 10)  # Ajustez ces valeurs selon vos donnÃ©es\n",
    "\n",
    "# Tracer les rÃ©sultats pour diffÃ©rentes combinaisons de Q et R\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for R in R_values:\n",
    "    for Q in Q_values:\n",
    "        steps, avg_speeds_per_particle, filtered_speeds_per_particle, avg_speeds_pop1, avg_speeds_pop2 = calculate_average_speed_per_cell_with_kalman(\n",
    "            df, max_step, DELTA_T, SPACE_SIZE, R, Q)\n",
    "        \n",
    "        # Tracer la vitesse moyenne filtrÃ©e pour chaque cellule en fonction de la valeur du pas de temps utilisÃ©\n",
    "        plt.subplot(len(R_values), len(Q_values), R_values.index(R) * len(Q_values) + Q_values.index(Q) + 1)\n",
    "        for particle, avg_speeds in filtered_speeds_per_particle.items():\n",
    "            plt.plot(steps, avg_speeds, marker='o', alpha=0.5, linewidth=0.1, color='blue')\n",
    "        \n",
    "        # Ajouter les courbes de la vitesse moyenne filtrÃ©e de chaque population\n",
    "        plt.plot(steps, avg_speeds_pop1, marker='o', alpha=0.5, linewidth=2, color='green', label='Population 1')\n",
    "        plt.plot(steps, avg_speeds_pop2, marker='o', alpha=0.5, linewidth=2, color='red', label='Population 2')\n",
    "\n",
    "        plt.xlabel('Intervalle de temps (pas)')\n",
    "        plt.ylabel('Vitesse moyenne filtrÃ©e [um/min]')\n",
    "        plt.title(f'R={R}, Q={Q}')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.xlim(x_limits)\n",
    "        plt.ylim(y_limits)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tracer les distributions des vitesses avant et aprÃ¨s le filtrage pour quelques particules\n",
    "particles_to_plot = list(df['particle'].unique())[:5]  # Choisir quelques particules pour tracer\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for particle in particles_to_plot:\n",
    "    plt.subplot(3, 2, particles_to_plot.index(particle) + 1)\n",
    "    original_speeds = np.array(avg_speeds_per_particle[particle])\n",
    "    filtered_speeds = np.array(filtered_speeds_per_particle[particle])\n",
    "    \n",
    "    plt.plot(steps, original_speeds, marker='o', color='red', alpha=0.5, label='Original')\n",
    "    plt.plot(steps, filtered_speeds, marker='o', color='blue', alpha=0.5, label='Filtered')\n",
    "    \n",
    "    plt.xlabel('Intervalle de temps (pas)')\n",
    "    plt.ylabel('Vitesse [um/min]')\n",
    "    plt.title(f'Particule {particle}')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlim(x_limits)\n",
    "    plt.ylim(y_limits)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour sous-Ã©chantillonner et calculer les vitesses moyennes pour chaque cellule\n",
    "def calculate_average_speed_per_cell(df, max_step, delta_t, space_size):\n",
    "    particles = df['particle'].unique()\n",
    "    steps = range(1, max_step + 1)\n",
    "    avg_speeds_per_particle = {particle: [] for particle in particles}\n",
    "    \n",
    "    for step in steps:\n",
    "        sub_sampled_df = df.groupby('particle').apply(lambda group: group.iloc[::step]).reset_index(drop=True)\n",
    "        sub_sampled_df = sub_sampled_df.groupby('particle').apply(lambda group: adjust_positions_xy(group, dt=delta_t*step, space_size=space_size)).reset_index(drop=True)\n",
    "        avg_speeds = sub_sampled_df.groupby('particle')['vitesse'].mean()\n",
    "        \n",
    "        for particle in particles:\n",
    "            if particle in avg_speeds:\n",
    "                avg_speeds_per_particle[particle].append(avg_speeds[particle])\n",
    "            else:\n",
    "                avg_speeds_per_particle[particle].append(np.nan)\n",
    "    \n",
    "    return steps, avg_speeds_per_particle\n",
    "\n",
    "# Calculer la vitesse moyenne pour chaque cellule et chaque pas de temps\n",
    "steps, avg_speeds_per_particle = calculate_average_speed_per_cell(df, max_step, DELTA_T, SPACE_SIZE)\n",
    "\n",
    "# Tracer la vitesse moyenne pour chaque cellule en fonction de la valeur du pas de temps utilisÃ©\n",
    "plt.figure(figsize=(12, 8))\n",
    "for particle, avg_speeds in avg_speeds_per_particle.items():\n",
    "    plt.plot(steps, avg_speeds, marker='o', linewidth=0.1, alpha=0.5, label=f'Cellule {particle}')\n",
    "\n",
    "plt.xlabel('Intervalle de temps utilisÃ© (nombre de pas)')\n",
    "plt.ylabel('Vitesse moyenne [um/min]')\n",
    "plt.title('Vitesse moyenne en fonction de l\\'intervalle de temps utilisÃ© pour chaque cellule')\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')  # DÃ©placer la lÃ©gende Ã  l'extÃ©rieur du graphique\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from filterpy.kalman import KalmanFilter\n",
    "\n",
    "# Fonction pour appliquer le filtre de Kalman Ã  une sÃ©rie de mesures\n",
    "def apply_kalman_filter(measurements, R=1e-1, Q=1e-5):\n",
    "    kf = KalmanFilter(dim_x=1, dim_z=1)\n",
    "    kf.x = np.array([0.])  # initial state\n",
    "    kf.F = np.array([[1.]])  # state transition matrix\n",
    "    kf.H = np.array([[1.]])  # Measurement function\n",
    "    kf.P = np.array([[1.]])  # covariance matrix\n",
    "    kf.R = R  # measurement noise\n",
    "    kf.Q = Q  # process noise\n",
    "    \n",
    "    filtered_measurements = []\n",
    "    for measurement in measurements:\n",
    "        kf.predict()\n",
    "        kf.update(np.array([measurement]))\n",
    "        filtered_measurements.append(kf.x[0])\n",
    "    \n",
    "    return filtered_measurements\n",
    "\n",
    "# Fonction pour sous-Ã©chantillonner et calculer les vitesses moyennes pour chaque cellule\n",
    "def calculate_average_speed_per_cell_with_kalman(df, max_step, delta_t, space_size, R=1e-2, Q=1e-5):\n",
    "    particles = df['particle'].unique()\n",
    "    steps = range(1, max_step + 1)\n",
    "    avg_speeds_per_particle = {particle: [] for particle in particles}\n",
    "    filtered_speeds_per_particle = {particle: [] for particle in particles}\n",
    "    \n",
    "    for step in steps:\n",
    "        sub_sampled_df = df.groupby('particle').apply(lambda group: group.iloc[::step]).reset_index(drop=True)\n",
    "        sub_sampled_df = sub_sampled_df.groupby('particle').apply(lambda group: adjust_positions_xy(group, dt=delta_t*step, space_size=space_size)).reset_index(drop=True)\n",
    "        avg_speeds = sub_sampled_df.groupby('particle')['vitesse'].mean()\n",
    "        \n",
    "        for particle in particles:\n",
    "            if particle in avg_speeds:\n",
    "                avg_speeds_per_particle[particle].append(avg_speeds[particle])\n",
    "            else:\n",
    "                avg_speeds_per_particle[particle].append(np.nan)\n",
    "        \n",
    "        # Appliquer le filtre de Kalman pour chaque particule\n",
    "        for particle in particles:\n",
    "            measurements = np.array(avg_speeds_per_particle[particle])\n",
    "            filtered_speeds = apply_kalman_filter(measurements, R, Q)\n",
    "            filtered_speeds_per_particle[particle] = filtered_speeds\n",
    "    \n",
    "    return steps, avg_speeds_per_particle, filtered_speeds_per_particle\n",
    "\n",
    "# Calculer la vitesse moyenne pour chaque cellule et chaque pas de temps\n",
    "max_step = 10  # Vous pouvez ajuster cette valeur selon vos besoins\n",
    "steps, avg_speeds_per_particle, filtered_speeds_per_particle = calculate_average_speed_per_cell_with_kalman(\n",
    "    df, max_step, DELTA_T, SPACE_SIZE, R=1e-2, Q=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracer la vitesse moyenne filtrÃ©e pour chaque cellule en fonction de la valeur du pas de temps utilisÃ©\n",
    "plt.figure(figsize=(12, 8))\n",
    "for particle, avg_speeds in filtered_speeds_per_particle.items():\n",
    "    plt.plot(steps, avg_speeds, marker='o', alpha=0.5, linewidth=0.1, color='blue', label=f'Cellule {particle}')\n",
    "\n",
    "plt.xlabel('Intervalle de temps utilisÃ© (nombre de pas)')\n",
    "plt.ylabel('Vitesse moyenne filtrÃ©e [um/min]')\n",
    "plt.title('Vitesse moyenne filtrÃ©e en fonction de l\\'intervalle de temps utilisÃ© pour chaque cellule')\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')  # DÃ©placer la lÃ©gende Ã  l'extÃ©rieur du graphique\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from filterpy.kalman import KalmanFilter\n",
    "\n",
    "# Fonction pour sous-Ã©chantillonner et calculer les vitesses moyennes pour chaque cellule\n",
    "def calculate_average_speed_per_cell(df, max_step, delta_t, space_size):\n",
    "    particles = df['particle'].unique()\n",
    "    steps = range(1, max_step + 1)\n",
    "    avg_speeds_per_particle = {particle: [] for particle in particles}\n",
    "    \n",
    "    for step in steps:\n",
    "        sub_sampled_df = df.groupby('particle').apply(lambda group: group.iloc[::step]).reset_index(drop=True)\n",
    "        sub_sampled_df = sub_sampled_df.groupby('particle').apply(lambda group: adjust_positions_xy(group, dt=delta_t*step, space_size=space_size)).reset_index(drop=True)\n",
    "        avg_speeds = sub_sampled_df.groupby('particle')['vitesse'].mean()\n",
    "        \n",
    "        for particle in particles:\n",
    "            if particle in avg_speeds:\n",
    "                avg_speeds_per_particle[particle].append(avg_speeds[particle])\n",
    "            else:\n",
    "                avg_speeds_per_particle[particle].append(np.nan)\n",
    "    \n",
    "    return steps, avg_speeds_per_particle\n",
    "\n",
    "# Fonction pour appliquer le filtre de Kalman Ã  une sÃ©rie de mesures\n",
    "def apply_kalman_filter(measurements, R=1e-2, Q=1e-5):\n",
    "    kf = KalmanFilter(dim_x=1, dim_z=1)\n",
    "    kf.x = np.array([0.])  # initial state\n",
    "    kf.F = np.array([[1.]])  # state transition matrix\n",
    "    kf.H = np.array([[1.]])  # Measurement function\n",
    "    kf.P = np.array([[1.]])  # covariance matrix\n",
    "    kf.R = R  # measurement noise\n",
    "    kf.Q = Q  # process noise\n",
    "    \n",
    "    filtered_measurements = []\n",
    "    for measurement in measurements:\n",
    "        kf.predict()\n",
    "        kf.update(np.array([measurement]))\n",
    "        filtered_measurements.append(kf.x[0])\n",
    "    \n",
    "    return filtered_measurements\n",
    "\n",
    "# Fonction pour sous-Ã©chantillonner et calculer les vitesses moyennes pour chaque cellule avec Kalman\n",
    "def calculate_average_speed_per_cell_with_kalman(df, max_step, delta_t, space_size, R=1e-2, Q=1e-5):\n",
    "    particles = df['particle'].unique()\n",
    "    steps = range(1, max_step + 1)\n",
    "    avg_speeds_per_particle = {particle: [] for particle in particles}\n",
    "    filtered_speeds_per_particle = {particle: [] for particle in particles}\n",
    "    \n",
    "    for step in steps:\n",
    "        sub_sampled_df = df.groupby('particle').apply(lambda group: group.iloc[::step]).reset_index(drop=True)\n",
    "        sub_sampled_df = sub_sampled_df.groupby('particle').apply(lambda group: adjust_positions_xy(group, dt=delta_t*step, space_size=space_size)).reset_index(drop=True)\n",
    "        avg_speeds = sub_sampled_df.groupby('particle')['vitesse'].mean()\n",
    "        \n",
    "        for particle in particles:\n",
    "            if particle in avg_speeds:\n",
    "                avg_speeds_per_particle[particle].append(avg_speeds[particle])\n",
    "            else:\n",
    "                avg_speeds_per_particle[particle].append(np.nan)\n",
    "        \n",
    "        # Appliquer le filtre de Kalman pour chaque particule\n",
    "        for particle in particles:\n",
    "            measurements = np.array(avg_speeds_per_particle[particle])\n",
    "            filtered_speeds = apply_kalman_filter(measurements, R, Q)\n",
    "            filtered_speeds_per_particle[particle] = filtered_speeds\n",
    "    \n",
    "    return steps, avg_speeds_per_particle, filtered_speeds_per_particle\n",
    "\n",
    "# Calculer la vitesse moyenne pour chaque cellule et chaque pas de temps\n",
    "max_step = 10  # Vous pouvez ajuster cette valeur selon vos besoins\n",
    "steps, avg_speeds_per_particle = calculate_average_speed_per_cell(df, max_step, DELTA_T, SPACE_SIZE)\n",
    "steps, avg_speeds_per_particle, filtered_speeds_per_particle = calculate_average_speed_per_cell_with_kalman(\n",
    "    df, max_step, DELTA_T, SPACE_SIZE, R=1e-1, Q=1e-5)\n",
    "\n",
    "# Tracer la vitesse moyenne pour chaque cellule en fonction de la valeur du pas de temps utilisÃ©\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Tracer les vitesses moyennes non filtrÃ©es (en rouge)\n",
    "for particle, avg_speeds in avg_speeds_per_particle.items():\n",
    "    plt.plot(steps, avg_speeds, marker='o', linewidth=0.1, alpha=0.5, color='red', label=f'Cellule {particle}' if particle == list(avg_speeds_per_particle.keys())[0] else \"\")\n",
    "\n",
    "# Tracer les vitesses moyennes filtrÃ©es (en bleu)\n",
    "for particle, avg_speeds in filtered_speeds_per_particle.items():\n",
    "    plt.plot(steps, avg_speeds, marker='o', alpha=0.5, linewidth=0.1, color='blue', label=f'Cellule {particle}' if particle == list(filtered_speeds_per_particle.keys())[0] else \"\")\n",
    "\n",
    "plt.xlabel('Intervalle de temps utilisÃ© (nombre de pas)')\n",
    "plt.ylabel('Vitesse moyenne [um/min]')\n",
    "plt.title('Vitesse moyenne en fonction de l\\'intervalle de temps utilisÃ© pour chaque cellule (Non filtrÃ©e en rouge, FiltrÃ©e en bleu)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Copier la colonne \"frame\" en \"time\" et renumÃ©roter les frames\n",
    "df['time'] = df['frame']\n",
    "df['frame'] = df.groupby('particle').cumcount() + 1\n",
    "\n",
    "# VÃ©rification\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# Fonction pour sous-Ã©chantillonner les donnÃ©es\n",
    "def subsample_data(df, step):\n",
    "    sub_sampled_df = df.groupby('particle').apply(lambda group: group.iloc[::step]).reset_index(drop=True)\n",
    "    sub_sampled_df['frame'] = sub_sampled_df.groupby('particle').cumcount() + 1\n",
    "    return sub_sampled_df\n",
    "\n",
    "# Fonction pour calculer le MSD\n",
    "def calculate_msd(df, max_step, delta_t, space_size):\n",
    "    msd_results = {}\n",
    "    steps = range(1, max_step + 1)\n",
    "    \n",
    "    for step in steps:\n",
    "        sub_sampled_df = subsample_data(df, step)\n",
    "        sub_sampled_df = sub_sampled_df.groupby('particle').apply(lambda group: adjust_positions_xy(group, dt=delta_t*step, space_size=space_size)).reset_index(drop=True)\n",
    "        msd = tp.imsd(sub_sampled_df, mpp=1, fps=1/(delta_t*step))\n",
    "        msd_results[step] = msd\n",
    "        print(f'Step {step}: MSD calculated for {len(msd)} particles.')\n",
    "    \n",
    "    return msd_results\n",
    "\n",
    "def calculate_slope_and_intercept(msd, lag_time_fit_short=5, range_long=(0.1, 1)):\n",
    "    slopes_short = []\n",
    "    intercepts_short = []\n",
    "    slopes_long = []\n",
    "    intercepts_long = []\n",
    "    \n",
    "    for col in msd.columns:\n",
    "        values = msd[col].values  # Convertir en numpy array\n",
    "        if len(values) >= lag_time_fit_short:\n",
    "            x_short = np.log(msd.index[:lag_time_fit_short] + 1e-15)\n",
    "            y_short = np.log(values[:lag_time_fit_short] + 1e-15)\n",
    "            slope_short, intercept_short, _, _, _ = stats.linregress(x_short, y_short)\n",
    "            slopes_short.append(slope_short)\n",
    "            intercepts_short.append(intercept_short)\n",
    "        # Filtrer les points dans la plage spÃ©cifiÃ©e pour les temps longs\n",
    "        mask_long = (msd.index >= range_long[0]) & (msd.index <= range_long[1])\n",
    "        if np.sum(mask_long) >= lag_time_fit_short:\n",
    "            x_long = np.log(msd.index[mask_long] + 1e-15)\n",
    "            y_long = np.log(values[mask_long] + 1e-15)\n",
    "            slope_long, intercept_long, _, _, _ = stats.linregress(x_long, y_long)\n",
    "            slopes_long.append(slope_long)\n",
    "            intercepts_long.append(intercept_long)\n",
    "    \n",
    "    return slopes_short, intercepts_short, slopes_long, intercepts_long\n",
    "\n",
    "# ParamÃ¨tres\n",
    "max_step = 10  # Vous pouvez ajuster cette valeur selon vos besoins\n",
    "delta_t = DELTA_T\n",
    "space_size = SPACE_SIZE\n",
    "df_pop1 = df[df['pop_tag']=='Population 1']\n",
    "df_pop2 = df[df['pop_tag']=='Population 2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le MSD pour chaque intervalle de temps\n",
    "msd_results = calculate_msd(df, max_step, delta_t, space_size)\n",
    "\n",
    "# Couleurs pour les courbes\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, max_step))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
